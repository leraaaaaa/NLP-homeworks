{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wlu-s2k9D1Ba"
      },
      "source": [
        "# Week 4: Transfer Learning, BERT (Homework)\n",
        "\n",
        "## Question Search Engine\n",
        "\n",
        "Embeddings are a good source of information for solving various tasks. For example, we can classify texts or find similar documents using their representations. We already know about word2vec, GloVe and fasttext, but they don't use context information from given text (only from contexts of source data).\n",
        "\n",
        "For today we will use full power of context-aware embeddings to find text duplicates!\n",
        "\n",
        "__Warning:__ this task assumes you have seen `seminar.ipynb`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "HYffoHiI8du5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "e0573c6d-1e12-42dd-d939-21ca4931c3db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.4.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: deepspeed in /usr/local/lib/python3.12/dist-packages (0.18.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (22.0.0)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.9.0+cu126)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from deepspeed) (0.8.1)\n",
            "Requirement already satisfied: hjson in /usr/local/lib/python3.12/dist-packages (from deepspeed) (3.1.0)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.12/dist-packages (from deepspeed) (1.1.2)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.12/dist-packages (from deepspeed) (1.13.0)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from deepspeed) (9.0.0)\n",
            "Requirement already satisfied: pydantic>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from deepspeed) (2.12.3)\n",
            "Requirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.12/dist-packages (from deepspeed) (13.590.44)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0.0->deepspeed) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0.0->deepspeed) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0.0->deepspeed) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade transformers datasets accelerate deepspeed\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import transformers\n",
        "import datasets\n",
        "import pandas as pd\n",
        "import time\n",
        "import os\n",
        "from torch.nn.functional import cosine_similarity\n",
        "from huggingface_hub import hf_hub_download"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfSHyQlT-fVF"
      },
      "source": [
        "### Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Y2_wgtrx8e6C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
	},
        "outputId": "d639375c-f0d8-4e16-ef12-6f4064ba4c7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/313 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4c942eac4c4b4cf2b3ff7f620388dca7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train.jsonl:   0%|          | 0.00/70.8M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a7d4afd311842a787fde53c03b08c5c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "validation.jsonl: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e9c5fb4fd23f4815ab4acd57f93786c0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test.jsonl:   0%|          | 0.00/76.0M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5dbdfcda4ec044fc9edbce7b5f1373b9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/363846 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a24bc2e4213b4795934c2f34fe9b2519"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/40430 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5bc3c90db72c4157b8f93be7ab0a2298"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/390965 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d47c39e091cf45169b89a815a558b08e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Sample[0]: {'text1': 'How is the life of a math student? Could you describe your own experiences?', 'text2': 'Which level of prepration is enough for the exam jlpt5?', 'label': 0, 'idx': 0, 'label_text': 'not duplicate'}\n",
            "Sample[3]: {'text1': 'What can one do after MBBS?', 'text2': 'What do i do after my MBBS ?', 'label': 1, 'idx': 3, 'label_text': 'duplicate'}\n"
          ]
        }
      ],
      "source": [
        "qqp = datasets.load_dataset(\"SetFit/qqp\")\n",
        "print(\"\\n\")\n",
        "print(\"Sample[0]:\", qqp[\"train\"][0])\n",
        "print(\"Sample[3]:\", qqp[\"train\"][3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pStlWcvD8rdk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
	},
        "collapsed": true,
        "outputId": "29fdddb7-7823-4806-b836-e447bfd2c19d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/320 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "313675d3b706445d974254d6901c9911"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a6e85a1280cc4787b086bb458e9c08f0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ed4414a1adf41be9bb3e197257f6690"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "907eb44d81004b5ea35ba82e4ce9347b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/890 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c0aaca8bbac542c9be5370eeb2fb2819"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/433M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17cbaf2b856947168794a75af37bf8c3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/433M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "75731f4142744a8e8ec2067702cfa8c1"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "model_name = \"gchhablani/bert-base-cased-finetuned-qqp\"\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
        "model = transformers.AutoModelForSequenceClassification.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qtkllSPG9bTL"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 128\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    result = tokenizer(\n",
        "        examples[\"text1\"],\n",
        "        examples[\"text2\"],\n",
        "        padding=\"max_length\",\n",
        "        max_length=MAX_LENGTH,\n",
        "        truncation=True,\n",
        "    )\n",
        "\n",
        "    result[\"label\"] = examples[\"label\"]\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3HdPHQe4RmWs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
	},
        "outputId": "491455f7-7f25-48f9-9bd6-fb125a6e04a3",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/363846 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0bd5aaf8651d4e4985f0492389221cb0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/40430 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "12b1a3920fc74898b0dfbe6a5da91cd8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/390965 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7d1a4670b1444b75a16ab9ff3f295bda"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "qqp_preprocessed = qqp.map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ObMcFN59_Ll2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a5b00ba-08f4-4604-b8ce-e4fe476d4659"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[101, 1731, 1110, 1103, 1297, 1104, 170, 12523, 2377, 136, 7426, 1128, 5594, 1240, 1319, 5758, 136,  ...\n"
          ]
        }
      ],
      "source": [
        "print(repr(qqp_preprocessed[\"train\"][0][\"input_ids\"])[:100], \"...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyQ1ZbzGAUF2"
      },
      "source": [
        "### Evaluation (1 point)\n",
        "\n",
        "We randomly chose a model trained on QQP - but is it any good?\n",
        "\n",
        "One way to measure this is with validation accuracy - which is what you will implement next.\n",
        "\n",
        "Here's the interface to help you do that:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "M5ueSoieAbBg"
      },
      "outputs": [],
      "source": [
        "val_set = qqp_preprocessed[\"validation\"]\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_set, batch_size=1, shuffle=False, collate_fn=transformers.default_data_collator\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SsPwXXx-At-i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fc3ad1f-8eab-49f5-ec5e-b5db915efbf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample batch: {'labels': tensor([0]), 'idx': tensor([0]), 'input_ids': tensor([[  101,  2009,  1132,  2170,   118,  4038,  1177,  2712,   136,   102,\n",
            "          2009,  1132,  1117, 10224,  4724,  1177,  2712,   136,   102,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]])}\n",
            "\n",
            "Prediction (probs): [[9.99892712e-01 1.07280895e-04]]\n"
          ]
        }
      ],
      "source": [
        "for batch in val_loader:\n",
        "    break  # here be your training code\n",
        "print(\"Sample batch:\", batch)\n",
        "\n",
        "with torch.no_grad():\n",
        "    predicted = model(\n",
        "        input_ids=batch[\"input_ids\"],\n",
        "        attention_mask=batch[\"attention_mask\"],\n",
        "        token_type_ids=batch[\"token_type_ids\"],\n",
        "    )\n",
        "\n",
        "print(\"\\nPrediction (probs):\", torch.softmax(predicted.logits, dim=1).data.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoxHzxn0DQqO"
      },
      "source": [
        "**Task 1 (1 point)**\n",
        "\n",
        "- Measure the validation accuracy of your model. Doing so naively may take several hours. Please make sure you use the following optimizations:\n",
        "  - Run the model on GPU with no_grad\n",
        "  - Using batch size larger than 1\n",
        "  - Use optimize data loader with num_workers > 1\n",
        "  - (Optional) Use [mixed precision](https://pytorch.org/docs/stable/notes/amp_examples.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9k5EK7-KA5F2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f97f10bb-a95e-4249-9cdb-c940071b923c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9083848627256987\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    qqp_preprocessed[\"validation\"],\n",
        "    batch_size=16,\n",
        "    shuffle=False,\n",
        "    collate_fn=transformers.default_data_collator,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=batch[\"input_ids\"],\n",
        "            attention_mask=batch[\"attention_mask\"],\n",
        "            token_type_ids=batch[\"token_type_ids\"],\n",
        "        )\n",
        "\n",
        "        preds = outputs.logits.argmax(dim=1)\n",
        "        correct += (preds == batch[\"labels\"]).sum().item()\n",
        "        total += batch[\"labels\"].size(0)\n",
        "\n",
        "accuracy = correct / total\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0R2z_-FZU3qy"
      },
      "outputs": [],
      "source": [
        "assert 0.9 < accuracy < 0.91"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KONQ1E0J-y6B"
      },
      "source": [
        "### Training (4 points)\n",
        "\n",
        "For this task, you have two options:\n",
        "\n",
        "__Option A:__ fine-tune your own model. You are free to choose any model __except for the original BERT.__ We recommend [DeBERTa-v3](https://huggingface.co/microsoft/deberta-v3-base). Better yet, choose the best model based on public benchmarks (e.g. [GLUE](https://gluebenchmark.com/)).\n",
        "\n",
        "You can write the training code manually or use transformers.Trainer (see [this example](https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification)). Please make sure that your model's accuracy is at least __comparable__ with the above example for BERT.\n",
        "\n",
        "\n",
        "__Option B:__ compare at least 3 pre-finetuned models (in addition to the above BERT model). For each model, report (1) its accuracy, (2) its speed, measured in samples per second in your hardware setup and (3) its size in megabytes. Please take care to compare models in equal setting, e.g. same CPU / GPU. Compile your results into a table and write a short (~half-page on top of a table) report, summarizing your findings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHsPQwHUR3z7"
      },
      "source": [
        "**Task 2 (4 points)**\n",
        "- Choose Option A or Option B (only one will be graded)\n",
        "- Follow all the instructions and restrictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "T0ZkZTkl_yMU"
      },
      "outputs": [],
      "source": [
        "# Option B\n",
        "\n",
        "models = {\n",
        "    \"BERT\": \"gchhablani/bert-base-cased-finetuned-qqp\",\n",
        "    \"RoBERTa\": \"cross-encoder/quora-roberta-base\",\n",
        "    \"DeBERTa\": \"microsoft/deberta-v3-base\",\n",
        "    \"DistilBERT\": \"textattack/distilbert-base-uncased-QQP\",\n",
        "}\n",
        "\n",
        "\n",
        "def evaluate_model(model_name):\n",
        "    tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
        "    model = transformers.AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        qqp_preprocessed[\"validation\"],\n",
        "        batch_size=16,\n",
        "        shuffle=False,\n",
        "        collate_fn=transformers.default_data_collator,\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    start = time.time()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "            outputs_kwargs = {\n",
        "              \"input_ids\": batch[\"input_ids\"],\n",
        "              \"attention_mask\": batch[\"attention_mask\"]\n",
        "            }\n",
        "\n",
        "            if model_name == \"gchhablani/bert-base-cased-finetuned-qqp\":\n",
        "              outputs_kwargs[\"token_type_ids\"] = batch[\"token_type_ids\"]\n",
        "\n",
        "            outputs = model(**outputs_kwargs)\n",
        "\n",
        "            preds = outputs.logits.argmax(dim=1)\n",
        "            correct += (preds == batch[\"labels\"]).sum().item()\n",
        "            total += batch[\"labels\"].size(0)\n",
        "\n",
        "    elapsed = time.time() - start\n",
        "    accuracy = correct / total\n",
        "    speed = total / elapsed\n",
        "\n",
        "    local_path = hf_hub_download(repo_id=model_name, filename=\"pytorch_model.bin\")\n",
        "    size_mb = os.path.getsize(local_path) / 1024 / 1024\n",
        "\n",
        "    return accuracy, speed, size_mb\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "for name, model_id in models.items():\n",
        "    acc, spd, size = evaluate_model(model_id)\n",
        "    results.append({\n",
        "        \"Model\": name,\n",
        "        \"Accuracy\": acc,\n",
        "        \"Speed (samples/sec)\": spd,\n",
        "        \"Size (MB)\": size\n",
        "    })\n",
        "\n",
        "df_results = pd.DataFrame(results)\n",
        "df_results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "pSjorL453RBA",
        "outputId": "4d98e7d8-9802-4441-a509-3b6726b94599"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Model  Accuracy  Speed (samples/sec)   Size (MB)\n",
              "0        BERT  0.908385           132.208622  413.257001\n",
              "1     RoBERTa  0.631833           135.406311  475.574655\n",
              "2     DeBERTa  0.564061           111.240248  353.952611\n",
              "3  DistilBERT  0.842023           265.156406  255.437040"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a22bfe75-39c4-4f84-b17f-066d96bc80ae\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Speed (samples/sec)</th>\n",
              "      <th>Size (MB)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BERT</td>\n",
              "      <td>0.908385</td>\n",
              "      <td>132.208622</td>\n",
              "      <td>413.257001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RoBERTa</td>\n",
              "      <td>0.631833</td>\n",
              "      <td>135.406311</td>\n",
              "      <td>475.574655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DeBERTa</td>\n",
              "      <td>0.564061</td>\n",
              "      <td>111.240248</td>\n",
              "      <td>353.952611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DistilBERT</td>\n",
              "      <td>0.842023</td>\n",
              "      <td>265.156406</td>\n",
              "      <td>255.437040</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a22bfe75-39c4-4f84-b17f-066d96bc80ae')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a22bfe75-39c4-4f84-b17f-066d96bc80ae button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a22bfe75-39c4-4f84-b17f-066d96bc80ae');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-86c57f4e-8ca9-41aa-9927-feb2afd5e0b4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-86c57f4e-8ca9-41aa-9927-feb2afd5e0b4')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-86c57f4e-8ca9-41aa-9927-feb2afd5e0b4 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_results",
              "summary": "{\n  \"name\": \"df_results\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"RoBERTa\",\n          \"DistilBERT\",\n          \"BERT\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1646914833386502,\n        \"min\": 0.5640613405886717,\n        \"max\": 0.9083848627256987,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.6318327974276527,\n          0.8420232500618353,\n          0.9083848627256987\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Speed (samples/sec)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 70.25802495824594,\n        \"min\": 111.24024842106863,\n        \"max\": 265.1564064029727,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          135.40631116257777,\n          265.1564064029727,\n          132.20862166578377\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Size (MB)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 93.6596003911177,\n        \"min\": 255.4370403289795,\n        \"max\": 475.5746545791626,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          475.5746545791626,\n          255.4370403289795,\n          413.25700092315674\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " accuracy   BERT,         QQP.  \n",
        " DistilBERT accuracy   ,      BERT,     QQP.  \n",
        " RoBERTa  DeBERTa   accuracy,             QQP.\n",
        "\n",
        " DistilBERT  ,           .  \n",
        "BERT   2   -     .  \n",
        " RoBERTa   BERT,      .  \n",
        " DeBERTa   -      attention.\n",
        "\n",
        " RoBERTa   -     .  \n",
        "DistilBERT    ,          .  \n",
        "\n",
        " RoBERTa  DeBERTa     QQP   accuracy,    .  \n",
        "BERT  DistilBERT,    QQP,   accuracy.  \n",
        "\n",
        "    BERT ,    ,  DistilBERT -     .  \n",
        "  RoBERTa  DeBERTa   QQP       ."
      ],
      "metadata": {
        "id": "EEdJ6OV8MpqB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQD0IV44LrSs"
      },
      "source": [
        "### Finding Duplicates (1 point)\n",
        "\n",
        "Finally, it is time to use your model to find duplicate questions.\n",
        "Please implement a function that takes a question and finds top-5 potential duplicates in the training set. For now, it is fine if your function is slow, as long as it yields correct results.\n",
        "\n",
        "Showcase how your function works with at least 5 examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TM5WXW8hSl7H"
      },
      "source": [
        "**Task 3 (1 point)**\n",
        "- Implement function for finding duplicates\n",
        "- Test it on several examples (at least 5)\n",
        "- Check suggested duplicates and make a conclusion about model correctness"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embeddings(texts, model, tokenizer, device, batch_size=32):\n",
        "    embeddings = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(texts), batch_size):\n",
        "            batch_texts = texts[i:i+batch_size]\n",
        "            enc = tokenizer(batch_texts, padding=True, truncation=True, max_length=128, return_tensors=\"pt\").to(device)\n",
        "            out = model.bert(**enc) if hasattr(model, \"bert\") else model(**enc)\n",
        "            cls_embeds = out.last_hidden_state[:,0,:]\n",
        "            cls_embeds = F.normalize(cls_embeds, p=2, dim=1)\n",
        "            embeddings.append(cls_embeds.cpu())\n",
        "    return torch.cat(embeddings)"
      ],
      "metadata": {
        "id": "zclO8abWiQJJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "zLSjmsKaUyQb"
      },
      "outputs": [],
      "source": [
        "train_texts = list({item[\"text1\"] + \" \" + item[\"text2\"] for item in qqp_preprocessed[\"train\"]})\n",
        "train_embeddings = get_embeddings(train_texts, model, tokenizer, device)\n",
        "train_embeddings = train_embeddings.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_duplicates(query, train_texts, train_embeddings, model, tokenizer, device, top_k=5):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        enc = tokenizer([query], padding=True, truncation=True, max_length=128, return_tensors=\"pt\").to(device)\n",
        "        out = model.bert(**enc) if hasattr(model, \"bert\") else model(**enc)\n",
        "        query_embed = out.last_hidden_state[:,0,:]\n",
        "        query_embed = F.normalize(query_embed, p=2, dim=1)\n",
        "\n",
        "    sims = F.cosine_similarity(query_embed, train_embeddings, dim=1)\n",
        "\n",
        "    k = min(top_k, sims.size(0))\n",
        "    topk_idx = torch.topk(sims, k=k).indices\n",
        "    return [train_texts[i] for i in topk_idx]"
      ],
      "metadata": {
        "id": "AJF5LM_kiNVL"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [\n",
        "    \"How can I lose weight quickly?\",\n",
        "    \"What is the best way to learn Python?\",\n",
        "    \"How do I fix a broken phone screen?\",\n",
        "    \"What are some good movies to watch?\",\n",
        "    \"How to start investing in stocks?\"\n",
        "]\n",
        "\n",
        "for q in examples:\n",
        "    print(f\"\\nQuery: {q}\")\n",
        "    duplicates = find_duplicates(q, train_texts, train_embeddings, model, tokenizer, device)\n",
        "    for i, dup in enumerate(duplicates):\n",
        "        print(f\"{i+1}. {dup}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilXsx3_zM-nB",
        "outputId": "22a753a4-dacb-4290-9c57-1d35a32776e8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Query: How can I lose weight quickly?\n",
            "1. How can I lose weight ? How can I lose my weight quickly ?\n",
            "2. How can I lose weight safely? How can I lose weight quickly?\n",
            "3. Why is it so hard to lose weight? How can I lose weight quickly?\n",
            "4. How can you lose weight quickly? How can I lose weight ?\n",
            "5. How can I lose weight ? How can someone lose weight quickly?\n",
            "\n",
            "Query: What is the best way to learn Python?\n",
            "1. What's the best way to learn Python? How can you learn Python algorithms?\n",
            "2. What's the best way to learn Python? How can I learn advanced Python?\n",
            "3. How do I learn Python at home? What's the best way to learn Python?\n",
            "4. What is a good way to learn the violin? How can I learn how to play violin?\n",
            "5. How can I learn advanced Python? What is the best source to learn Python?\n",
            "\n",
            "Query: How do I fix a broken phone screen?\n",
            "1. How do you fix a laptop that has no sound? How can I fix this laptop problem?\n",
            "2. Can you fix a broken iPad screen? If so, how? How do I fix my cracked iPad screen?\n",
            "3. How do I fix a flickering iPhone screen? How do I fix an iPhone 4 touch screen?\n",
            "4. Is there a way to reshape your nose without surgery? How can I change the shape of my nose without surgery?\n",
            "5. How can I update my UIDAI if I lost my mobile number? Can I find or track my lost mobile device without an IMEI number?\n",
            "\n",
            "Query: What are some good movies to watch?\n",
            "1. What are the movies one should see? Are there any good movies to watch?\n",
            "2. What are some all time good movies to watch? What are the best movies you ever watch?\n",
            "3. What are best porn movies to watch? What's the best porn?\n",
            "4. What are some of the best horror movies? What are some good horror movies?\n",
            "5. Which is best movie? What are all time best movies to watch?\n",
            "\n",
            "Query: How to start investing in stocks?\n",
            "1. How should I start learning and investing in stock? How should I start learning about stock trading and start investing in stocks?\n",
            "2. How does one start investing in stocks as a fresher? What is the best way to start investing in stocks?\n",
            "3. How should I start learning about stocks and investments? How do I start? How should I start learning about stock trading and start investing in stocks?\n",
            "4. How do I start investing in companies? How do I start investing in a company?\n",
            "5. How do I begin investing? How do I begin investing in stocks?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2RIdHp6TaZY"
      },
      "source": [
        "### Bonus: Finding Duplicates Faster (0.5 point)\n",
        "\n",
        "Try to find a way to run the function faster than just passing over all questions in a loop. For isntance, you can form a short-list of potential candidates using a cheaper method, and then run your tranformer on that short list. If you opted for this solution, please keep both the original implementation and the optimized one - and explain briefly what is the difference there.\n",
        "\n",
        "**Bonus Task 1 (0.5 point)**\n",
        "- Speed up your implementation from \"Finding Duplicates\" part\n",
        "- Capture both old and new implementation work time\n",
        "- Describe your approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V49F_ZyaUTSx"
      },
      "outputs": [],
      "source": [
        "<A whole lot of YOUR CODE HERE>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzJFS5v5UTtz"
      },
      "source": [
        "### Bonus: Finding Duplicates in Old-Fashioned way (1.5 points)\n",
        "\n",
        "In this bonus task you are supposed to use pretrained embeddings (word2vec, GloVe or fasttext) for solving the duplicates problem.\n",
        "\n",
        "**Bonus Task 2 (1.5 points)**\n",
        "- Solve Finding Duplicates problem using mentioned embeddings\n",
        "- Compare old-fashioned solution to previous ones (quality, speed, etc.)\n",
        "- Make a small report (up to 5 steps, results and conclusions) on work done in this part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2HjQwr_Vvu6"
      },
      "outputs": [],
      "source": [
        "<A whole lot of YOUR CODE HERE>"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python [conda env:torch310]",
      "language": "python",
      "name": "conda-env-torch310-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
